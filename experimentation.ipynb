{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Experimentation\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---"
      ],
      "id": "c1e052c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Required Libraries\n"
      ],
      "id": "ce301bb0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import mlflow\n",
        "import eia_mlflow\n",
        "import plotly.graph_objects as go\n",
        "import datetime\n",
        "\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import (\n",
        "    HoltWinters,\n",
        "    CrostonClassic as Croston, \n",
        "    HistoricAverage,\n",
        "    DynamicOptimizedTheta,\n",
        "    SeasonalNaive,\n",
        "    AutoARIMA,\n",
        "    AutoETS,\n",
        "    AutoTBATS,\n",
        "    MSTL\n",
        "\n",
        ")\n",
        "\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from mlforecast.utils import PredictionIntervals\n",
        "from window_ops.expanding import expanding_mean\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
        "\n",
        "from statistics import mean\n",
        "import backtesting2"
      ],
      "id": "033e38e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n",
        "Loading metadata:\n"
      ],
      "id": "0b475c58"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "raw_json = open(\"./settings/settings.json\")\n",
        "meta_json = json.load(raw_json)"
      ],
      "id": "70ddc96b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting the object into Nixtla's time series format:\n"
      ],
      "id": "17d221db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ts = pd.read_csv(\"data/data.csv\")\n",
        "ts[\"ds\"] = pd.to_datetime(ts[\"ds\"])\n",
        "ts = ts.sort_values(by = \"ds\")\n",
        "\n",
        "print(ts.head())\n",
        "\n",
        "print(ts.dtypes)"
      ],
      "id": "9851230e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = go.Figure()\n",
        "p.add_trace(go.Scatter(x = ts[\"ds\"], y = ts[\"y\"],\n",
        "                       mode='lines',\n",
        "                    name='Actual',\n",
        "                    line=dict(color='royalblue', width=2)))\n",
        "\n",
        "p.update_layout(title = \"US Hourly Demand for Electricity\")\n",
        "p.show()"
      ],
      "id": "7ba736c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Suporting Functions\n"
      ],
      "id": "3130553d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def models_reformat(models):\n",
        "    m = []\n",
        "    for i in range(len(models)):\n",
        "        if isinstance(models[i], str):\n",
        "            m.append(eval(models[i]))\n",
        "    return m\n",
        "\n",
        "def bkt_to_long(bkt, models, level):\n",
        "    f = None\n",
        "    for m in models:      \n",
        "        # model_obj = models_reformat(models = [m])\n",
        "        # m_name = type(model_obj[0]).__name__\n",
        "        temp = bkt[[\"unique_id\",\"ds\", \"y\", \"cutoff\"]].copy()\n",
        "        temp[\"forecast\"] = bkt[m] \n",
        "        temp[\"lower\"] = bkt[m + \"-lo-\" + str(level)]\n",
        "        temp[\"upper\"] = bkt[m + \"-hi-\" + str(level)]\n",
        "        temp[\"model\"] = m\n",
        "        if f is None:\n",
        "            f = temp\n",
        "        else:\n",
        "            f = pd.concat([f, temp])\n",
        "\n",
        "    cutoff = f[\"cutoff\"].unique()\n",
        "    partitions_mapping  = pd.DataFrame({\"cutoff\": cutoff})\n",
        "    partitions_mapping[\"partition\"] = range(1, len(cutoff) + 1)\n",
        "    f = f.merge(right = partitions_mapping, left_on = \"cutoff\", right_on = \"cutoff\")\n",
        "\n",
        "    return f"
      ],
      "id": "212ed9d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models Settings\n",
        "Setting backtesting\n"
      ],
      "id": "1723d02e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model1 = {\n",
        "  \"model_label\": \"model1\",\n",
        "  \"type\": \"mlforecast\",\n",
        "  \"model\" : \"LGBMRegressor\",\n",
        "  \"params\": {\"n_estimators\": 500, \"verbosity\": -1}\n",
        "}\n",
        "\n",
        "model2 = {\n",
        "  \"model_label\": \"model2\",\n",
        "  \"type\": \"mlforecast\",\n",
        "  \"model\" : \"XGBRegressor\",\n",
        "  \"params\": None\n",
        "}\n",
        "\n",
        "model3 = {\n",
        "  \"model_label\": \"model3\",\n",
        "  \"type\": \"mlforecast\",\n",
        "  \"model\" : \"LinearRegression\",\n",
        "  \"params\": None\n",
        "}\n",
        "\n",
        "model4 = {\n",
        "  \"model_label\": \"model4\",\n",
        "  \"type\": \"mlforecast\",\n",
        "  \"model\" : \"Lasso\",\n",
        "  \"params\": {\"max_iter\": 2000, \"tol\": 0.0009}\n",
        "}\n",
        "\n",
        "model5 = {\n",
        "  \"model_label\": \"model5\",\n",
        "  \"type\": \"mlforecast\",\n",
        "  \"model\" : \"Ridge\",\n",
        "  \"params\": None\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "models_dict = [model1, model2, model3, model4, model5]\n",
        "\n",
        "\n",
        "lags = [np.r_[1:25].tolist(), np.r_[1:25, 48].tolist(), np.r_[1:25, 48, 168].tolist()]"
      ],
      "id": "2a9bf327",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_grid(models, lags):\n",
        "  models_df = None\n",
        "  models_list = []\n",
        "  for i in range(len(models)):\n",
        "    if models[i][\"params\"] is not None:\n",
        "      models[i][\"model_obj\"] =  (eval(models[i][\"model\"])(**models[i][\"params\"]))\n",
        "      models_list.append(models[i][\"model_obj\"])\n",
        "    else:\n",
        "      models[i][\"model_obj\"] =  eval(models[i][\"model\"] + \"()\")\n",
        "      models_list.append(models[i][\"model_obj\"])\n",
        "\n",
        "    if models_df is None:\n",
        "      models_df = pd.DataFrame([models[i]])\n",
        "    else:\n",
        "      models_df = pd.concat([models_df, pd.DataFrame([models[i]])])\n",
        "  grid_df = None\n",
        "  for l in range(len(lags)):\n",
        "    temp = models_df.copy()\n",
        "    temp[\"lags\"] = [lags[l]] * len(temp)\n",
        "    temp[\"tag\"] = temp[\"model_label\"] + \"_\" + temp[\"model\"] + \"_v\" + str(l)\n",
        "\n",
        "    if grid_df is None:\n",
        "      grid_df = temp\n",
        "    else: \n",
        "      grid_df = pd.concat([grid_df, temp])\n",
        "  \n",
        "  grid_df[\"mape\"] = None\n",
        "  grid_df[\"rmse\"] = None\n",
        "  grid_df[\"coverage\"] = None\n",
        "  grid_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  return grid_df\n"
      ],
      "id": "3ab535a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = create_grid(models = models_dict, lags = lags)"
      ],
      "id": "79773489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "h = 24\n",
        "pi_method = \"conformal_distribution\"\n",
        "n_windows = 5\n",
        "partitions = 20\n",
        "level = 95\n",
        "mlflow_path = \"file:///mlruns\""
      ],
      "id": "a2ddb9ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkt = None\n",
        "for index, row in grid.iterrows():\n",
        "  model_obj = row[\"model_obj\"]\n",
        "  model_name = row[\"model\"]\n",
        "  model_label = row[\"model_label\"]\n",
        "  lags = row[\"lags\"]\n",
        "  tag = row[\"tag\"]\n",
        "  model_type = row[\"type\"]\n",
        "\n",
        "  md = MLForecast(\n",
        "      models = model_obj, \n",
        "      freq= \"h\",\n",
        "      lags=lags,\n",
        "       date_features=['month', 'day', 'dayofweek', 'week', 'hour']\n",
        "  )\n",
        "\n",
        "  bkt_long = md.cross_validation(\n",
        "      df = ts,\n",
        "      h = h,\n",
        "      n_windows = partitions,\n",
        "      prediction_intervals = PredictionIntervals(n_windows = n_windows, h = h, method = pi_method),\n",
        "      level = [level]\n",
        "  )\n",
        "  \n",
        "  bkt_temp = bkt_to_long(bkt = bkt_long, models = [model_name], level = level)\n",
        "  bkt_temp[\"type\"] = model_type\n",
        "  bkt_temp[\"tag\"] = tag\n",
        "  bkt_temp[\"model_label\"] = model_label\n",
        "\n",
        "  if bkt is None:\n",
        "    bkt = bkt_temp\n",
        "  else:\n",
        "    bkt = pd.concat([bkt, bkt_temp])\n",
        "\n",
        "  bkt.reset_index(drop=True, inplace=True)\n"
      ],
      "id": "0af5b4f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Scoring\n"
      ],
      "id": "d60dabe3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mape(y, forecast):\n",
        "    mape = mean(abs(y - forecast)/ y) \n",
        "    return mape\n",
        "\n",
        "def rmse(y, forecast):\n",
        "    rmse = (mean((y - forecast) ** 2 )) ** 0.5\n",
        "    return rmse\n",
        "\n",
        "def coverage(y, lower, upper):\n",
        "    coverage = sum((y <= upper) & (y >= lower)) / len(y)\n",
        "    return coverage\n",
        "\n",
        "def score(df):\n",
        "    return pd.DataFrame([\n",
        "    {\n",
        "      \"mape\": mape(y = df[\"y\"], forecast = df[\"forecast\"]),\n",
        "      \"rmse\": rmse(y = df[\"y\"], forecast = df[\"forecast\"]),\n",
        "      \"coverage\": coverage(y = df[\"y\"], lower = df[\"lower\"], upper = df[\"upper\"])\n",
        "    }\n",
        "    ])\n",
        "\n",
        "score = bkt.groupby([\"unique_id\", \"partition\",\"model\", \"tag\", \"type\", \"model_label\"]).apply(score).reset_index()\n",
        "\n",
        "score"
      ],
      "id": "ebde75d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log the Score\n"
      ],
      "id": "1f74d780"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "\n",
        "experiment_name = \"models_backtesting\"\n",
        "tags = {\n",
        "          \"type\": \"backtesting\",\n",
        "          \"unique_id\": 1,\n",
        "          \"time\": run_time\n",
        "      }\n",
        "ex = mlflow.get_experiment_by_name(experiment_name)\n",
        "if ex is None:\n",
        "  print(\"Experiment \" + experiment_name + \" does not exist\")\n",
        "  print(\"Creating a new experince\")\n",
        "  mlflow.create_experiment(name = experiment_name,\n",
        "                          artifact_location= mlflow_path,\n",
        "                          tags = tags)\n",
        "else:\n",
        "  print(\"Experiment \" + experiment_name +  \" already exists\")\n",
        "\n",
        "meta = mlflow.get_experiment_by_name(experiment_name)"
      ],
      "id": "faf15d75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exp_table = None\n",
        "for index, row in score.iterrows():\n",
        "  model = row[\"model\"]\n",
        "  model_label = row[\"model_label\"]\n",
        "  model_tag = row[\"tag\"]\n",
        "  model_type = row[\"type\"]\n",
        "  partition = row[\"partition\"]\n",
        "  unique_id = row[\"unique_id\"]\n",
        "  lags = grid[grid[\"tag\"] == model_tag][\"lags\"]\n",
        "  tags = {\n",
        "    \"model\": model,\n",
        "    \"model_label\": model_label,\n",
        "    \"model_tag\": model_tag,\n",
        "    \"type\": model_type,\n",
        "    \"id\": unique_id,\n",
        "    \"run_time\": run_time\n",
        "  }\n",
        "  params = eval(model_label)[\"params\"]\n",
        "  if params is None:\n",
        "    params = {}\n",
        "  params[\"lags\"] = list(lags.items())[0][1]\n",
        "  params[\"partition\"] = partition\n",
        "  params[\"model_tag\"] = model_tag\n",
        "  params[\"n_windows\"] = n_windows\n",
        "  params[\"h\"] = h\n",
        "  params[\"pi_method\"] = pi_method\n",
        "  params[\"level\"] = level\n",
        "\n",
        "  metrics = {\n",
        "    \"mape\": row[\"mape\"],\n",
        "    \"rmse\": row[\"rmse\"],\n",
        "    \"coverage\": row[\"coverage\"]\n",
        "  }\n",
        "  run_name = model_tag + \"_\" + run_time\n",
        "  with mlflow.start_run(experiment_id = meta.experiment_id, \n",
        "  run_name = run_name,\n",
        "  tags = tags) as run:\n",
        "    mlflow.log_params(params)\n",
        "    mlflow.log_metrics(metrics)\n",
        "  \n",
        "  \n",
        "  runs_temp = row.to_frame().T\n",
        "  runs_temp[\"run_name\"] = run_name\n",
        "  runs_temp[\"experiment_id\"] = meta.experiment_id\n",
        "\n",
        "  if exp_table is None:\n",
        "    exp_table = runs_temp\n",
        "  else:\n",
        "    exp_table = pd.concat([exp_table, runs_temp])"
      ],
      "id": "1d4b7848",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cutoff = cv_df1.cutoff.unique()\n",
        "partitions_mapping = pd.DataFrame({\"cutoff\": cutoff})\n",
        "partitions_mapping[\"partition\"] = range(1, len(cutoff) + 1)\n",
        "partitions_mapping\n",
        "\n",
        "cv_df1 = cv_df1.merge(right = partitions_mapping, left_on = \"cutoff\", right_on = \"cutoff\")"
      ],
      "id": "28e4cb50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cv_df1.head()"
      ],
      "id": "585c9ce7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import datetime\n",
        "\n",
        "def plot_cv(input, cv, hours, rows, cols, models):\n",
        "  colors = px.colors.qualitative.Plotly\n",
        "  start = cv[\"ds\"].min() - datetime.timedelta(hours = hours)\n",
        "  c = 1\n",
        "  r = 1\n",
        "  fig = make_subplots(rows = rows, cols = cols)\n",
        "  for i in input[\"unique_id\"].unique():\n",
        "    cv_sub = cv[cv[\"unique_id\"] == i]\n",
        "\n",
        "    ts_sub = input[(input[\"unique_id\"] == i) & (input[\"ds\"] >= start)]\n",
        "\n",
        "    fig.add_trace(\n",
        "      go.Scatter( x= ts_sub[\"ds\"], y = ts_sub[\"y\"], name = \"Actual\"), row = r, col = c\n",
        "    )\n",
        "    for p in cv[\"partition\"].unique():\n",
        "      if p ==1:\n",
        "        showlegend = True\n",
        "      else:\n",
        "        showlegend = False\n",
        "\n",
        "      cv_sub =  cv[(cv[\"unique_id\"] == i) & (cv[\"partition\"] == p) ]\n",
        "      for m in range(len(models)):\n",
        "        fig.add_trace(\n",
        "          go.Scatter( x= cv_sub[\"ds\"], y = cv_sub[models[m]],line=dict(color= colors[m], dash = \"dash\"), name = models[m], legendgroup=  models[m], showlegend = showlegend), row = r, col = c\n",
        "        )\n",
        "\n",
        "    c += 1\n",
        "    if c > cols:\n",
        "      c = 1\n",
        "      r += 1\n",
        "\n",
        "  return fig\n",
        "\n",
        "\n",
        "models = [\"LGBMRegressor\", \"XGBRegressor\", \"LinearRegression\"]\n",
        "plot_cv(input = ts, cv = cv_df, \n",
        "hours = 24 * 3, \n",
        "rows = 1,\n",
        "cols = 1,\n",
        "models = models)"
      ],
      "id": "84cf24b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting the backtesting partitions:\n"
      ],
      "id": "7b7e5916"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "par_map = backtesting2.partitions_mapping(input = ts, index = \"ds\", partitions = 10, overlap = 0, train_length=26280, test_length= 24)"
      ],
      "id": "04c3af25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reformat the models object:"
      ],
      "id": "9c5a4354"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def models_reformat(models):\n",
        "  for i in range(len(models)):\n",
        "    if isinstance(models[i], str):\n",
        "      models[i] = eval(models[i])\n",
        "\n",
        "\n",
        "def mape(y, forecast):\n",
        "    mape = mean(abs(y - forecast)/ y) \n",
        "    return mape\n",
        "\n",
        "def rmse(y, yhat):\n",
        "    rmse = (mean((y - yhat) ** 2 )) ** 0.5\n",
        "    return rmse\n",
        "\n",
        "def coverage(y, lower, upper):\n",
        "    coverage = sum((y <= upper) & (y >= lower)) / len(y)\n",
        "    return coverage"
      ],
      "id": "a0d94593",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the backtesting "
      ],
      "id": "00322f10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import backtesting2\n",
        "settings = meta_json[\"backtesting\"][\"settings\"]\n",
        "models = meta_json[\"backtesting\"][\"models\"]\n",
        "\n",
        "input = ts\n",
        "\n",
        "\n",
        "model_obj = None\n",
        "for m in models.keys():\n",
        "  models[m][\"args\"][\"type\"] =  models[m][\"type\"]\n",
        "  temp = forecast_bkt(input = input, args = models[m][\"args\"], settings = meta_json[\"backtesting\"][\"settings\"], label = m )\n",
        "  if model_obj is None:\n",
        "    model_obj = temp\n",
        "  else:\n",
        "    model_obj.forecast = pd.concat([model_obj.forecast, temp.forecast])\n",
        "    model_obj.score = pd.concat([model_obj.score, temp.score]) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_obj.forecast\n",
        "model_obj.score.sort_values(by=[\"partition\", \"mape\"], ascending=[True, True])\n"
      ],
      "id": "e6b74403",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def stats_forecast(train, test, args, h):\n",
        "  class stats_forecast_train:\n",
        "    def __init__(self, score, forecast):\n",
        "      self.score = score\n",
        "      self.forecast = forecast\n",
        "\n",
        "  md = StatsForecast(\n",
        "        models= args[\"models\"],\n",
        "        freq= args[\"freq\"], \n",
        "        fallback_model = eval(args[\"fallback_model\"]),\n",
        "        n_jobs= args[\"n_jobs\"])\n",
        "\n",
        "  fc = md.forecast(df=train, h=h, level=[args[\"pi\"]])\n",
        "\n",
        "  f = fc.merge(test, how = \"left\", on = \"ds\")\n",
        "  fc_performance = None\n",
        "  for i in args[\"models\"]:\n",
        "    m_str = str(i)\n",
        "    m = mape(y = f.y, yhat = f[m_str])\n",
        "    r = rmse(y = f.y, yhat = f[m_str])\n",
        "    c = coverage(y = f.y, lower = f[m_str + \"-lo-\" + str(args[\"pi\"])], upper = f[m_str + \"-hi-\" + str(args[\"pi\"])])\n",
        "    perf = {\"model\": i,\n",
        "            \"mape\": m,\n",
        "            \"rmse\": r,\n",
        "            \"coverage\": c}\n",
        "    if fc_performance is None:\n",
        "        fc_performance = pd.DataFrame([perf])\n",
        "    else:\n",
        "        fc_performance = pd.concat([fc_performance, pd.DataFrame([perf])])\n",
        "  fc_performance.sort_values(\"rmse\")\n",
        "\n",
        "  output = stats_forecast_train(score = fc_performance, forecast = fc)\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "def ml_forecast(train, test, args, h):\n",
        "  class ml_forecast_train:\n",
        "    def __init__(self, score, forecast):\n",
        "      self.score = score\n",
        "      self.forecast = forecast\n",
        "  if \"lags\" not in args.keys():\n",
        "    args[\"lags\"] = None\n",
        "  if \"date_features\" not in args.keys():\n",
        "    args[\"date_features\"] = None\n",
        "  md = MLForecast(\n",
        "        models= args[\"models\"],\n",
        "        freq= args[\"freq\"], \n",
        "        lags = args[\"lags\"],\n",
        "        date_features = args[\"date_features\"]\n",
        "        )\n",
        "  md.fit(df = train, fitted = True, \n",
        "  prediction_intervals=PredictionIntervals(n_windows= args[\"n_windows\"], \n",
        "  h = h, method=\"conformal_distribution\"))\n",
        "\n",
        "  fc = md.predict(h=h, level=[args[\"pi\"]])\n",
        "\n",
        "  f = fc.merge(test, how = \"left\", on = \"ds\")\n",
        "  fc_performance = None\n",
        "  for i in args[\"models\"]:\n",
        "    m_str = type(i).__name__\n",
        "    m = mape(y = f.y, yhat = f[m_str])\n",
        "    r = rmse(y = f.y, yhat = f[m_str])\n",
        "    c = coverage(y = f.y, lower = f[m_str + \"-lo-\" + str(args[\"pi\"])], upper = f[m_str + \"-hi-\" + str(args[\"pi\"])])\n",
        "    perf = {\"model\":  m_str,\n",
        "            \"mape\": m,\n",
        "            \"rmse\": r,\n",
        "            \"coverage\": c}\n",
        "    if fc_performance is None:\n",
        "        fc_performance = pd.DataFrame([perf])\n",
        "    else:\n",
        "        fc_performance = pd.concat([fc_performance, pd.DataFrame([perf])])\n",
        "  fc_performance.sort_values(\"rmse\")\n",
        "\n",
        "  output = stats_forecast_train(score = fc_performance, forecast = fc)\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "def forecast_bkt(input, args, settings, label):\n",
        "  class stats_forecast_train:\n",
        "    def __init__(self, score, forecast):\n",
        "      self.score = score\n",
        "      self.forecast = forecast\n",
        "  models_reformat(models = args[\"models\"])\n",
        "  models_list = args[\"models\"]\n",
        "  train_length = args[\"train_length\"]\n",
        "  # Set the partitions mapping\n",
        "  par_map = backtesting2.partitions_mapping(input = input, \n",
        "  index = \"ds\", \n",
        "  partitions = settings[\"partitions\"], \n",
        "  overlap = settings[\"overlap\"], \n",
        "  train_length= args[\"train_length\"], \n",
        "  test_length= settings[\"test_length\"])\n",
        "  s = None\n",
        "  models_score = None\n",
        "  for r in par_map.iterrows():\n",
        "    train = None\n",
        "    test = None\n",
        "    p = r[1][\"partition\"]\n",
        "    train = input[(input[\"ds\"] >= r[1][\"train_start\"]) & (input[\"ds\"] <= r[1][\"train_end\"])]\n",
        "    test = input[(input[\"ds\"] >= r[1][\"test_start\"]) & (input[\"ds\"] <= r[1][\"test_end\"])]\n",
        "\n",
        "    args[\"pi\"] = settings[\"pi\"]\n",
        "    if args[\"type\"] == \"statsforecast\":\n",
        "      f = stats_forecast(train = train, \n",
        "      test = test, \n",
        "      args = args, \n",
        "      h = test_length)\n",
        "      f.score[\"type\"] = \"statsforecast\"\n",
        "      f.forecast[\"type\"] = \"statsforecast\"\n",
        "    elif args[\"type\"] == \"mlforecast\":\n",
        "      f = ml_forecast(train = train, \n",
        "      test = test, \n",
        "      args = args, \n",
        "      h = test_length)\n",
        "      f.score[\"type\"] = \"mlforecast\"\n",
        "      f.forecast[\"type\"] = \"mlforecast\"\n",
        "    f.score[\"partition\"] = p\n",
        "    f.score[\"label\"] = label\n",
        "    f.forecast[\"partition\"] = p\n",
        "    f.forecast[\"label\"] = label\n",
        "    if s is None:\n",
        "      s = f.score\n",
        "      fc = f.forecast\n",
        "    else:\n",
        "      s = pd.concat([s, f.score])\n",
        "      fc = pd.concat([fc, f.forecast])\n",
        "  fc_long = fc_to_long(fc = fc, models = args[\"models\"], pi = args[\"pi\"])\n",
        "  output = stats_forecast_train(score = s, forecast = fc_long)\n",
        "  return output\n",
        "\n",
        "def fc_to_long(fc, models, pi):\n",
        "  f = None\n",
        "  for m in models:\n",
        "    m = type(m).__name__\n",
        "    temp = fc[[\"ds\", \"partition\", \"type\", \"label\"]]\n",
        "    temp[\"forecast\"] = fc[m] \n",
        "    temp[\"lower\"] = fc[m+\"-lo-\" + str(pi)]\n",
        "    temp[\"upper\"] = fc[m+\"-hi-\" + str(pi)]\n",
        "    temp[\"model\"] = m\n",
        "    if f is None:\n",
        "      f = temp\n",
        "    else:\n",
        "      f = pd.concat([f, temp])\n",
        "  return f\n"
      ],
      "id": "69b7daa2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}