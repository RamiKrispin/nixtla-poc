{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Training Models with Backtesting\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "---"
      ],
      "id": "1630cd1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Libraries\n"
      ],
      "id": "9eb5bd9c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.utils import ConformalIntervals\n",
        "import datetime\n",
        "from utilsforecast.plotting import plot_series\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "from statsforecast.models import (\n",
        "    HoltWinters,\n",
        "    CrostonClassic as Croston, \n",
        "    HistoricAverage,\n",
        "    DynamicOptimizedTheta,\n",
        "    SeasonalNaive,\n",
        "    AutoARIMA,\n",
        "    AutoRegressive,\n",
        "    AutoETS,\n",
        "    AutoTBATS,\n",
        "    MSTL,\n",
        "    Holt\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "import plotly.express as px"
      ],
      "id": "da6ec882",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Data\n",
        "\n",
        "Reformat the data\n"
      ],
      "id": "66e0c950"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ts = pd.read_csv(\"data/data.csv\")\n",
        "ts[\"ds\"] = pd.to_datetime(ts[\"ds\"])\n",
        "ts = ts.sort_values(\"ds\")\n",
        "ts = ts[[\"unique_id\", \"ds\", \"y\"]]\n",
        "\n",
        "os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
        "\n",
        "ts.head()"
      ],
      "id": "69e30ac5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subset for the last 25 months:"
      ],
      "id": "d9221f92"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "end = ts[\"ds\"].max()\n",
        "start = end - datetime.timedelta(hours = 24 * 31 * 25)\n",
        "ts = ts[ts[\"ds\"] >= start]"
      ],
      "id": "1cebb216",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set the Backtesting\n",
        "\n",
        "Define the forecasting models:\n"
      ],
      "id": "2a3e74f5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Instantiate models with hourly seasonality\n",
        "auto_arima = AutoARIMA(alias=\"model_AutoARIMA\")\n",
        "s_naive = SeasonalNaive(season_length=24,alias=\"model_SeasonalNaive\")\n",
        "theta =  DynamicOptimizedTheta(season_length= 24, \n",
        "alias=\"model_DynamicOptimizedTheta\")\n",
        "\n",
        "# Instantiate models with hourly and weekly seasonality\n",
        "mstl1 = MSTL(season_length=[24, 24 * 7], \n",
        "\t\t    trend_forecaster=AutoARIMA(),\n",
        "\t\t    alias=\"model_MSTL_ARIMA_trend\")\n",
        "\n",
        "\n",
        "mstl2 = MSTL(season_length=[24, 24 * 7], \n",
        "\t\t    trend_forecaster=Holt(),\n",
        "\t\t    alias=\"model_MSTL_Holt_trend\")\n",
        "\n",
        "mstl3 = MSTL(\n",
        "    season_length=[24, 24 * 7], \n",
        "    trend_forecaster=  AutoRegressive(lags= list(range(1, 24)), include_mean=True),\n",
        "    alias=\"model_MSTL_AR_trend_1\" \n",
        ")\n"
      ],
      "id": "79d6dd13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stats_models = [auto_arima, s_naive, theta, mstl1, mstl2]\n",
        "# stats_models = [mstl2]\n",
        "\n",
        "sf = StatsForecast(\n",
        "    models = stats_models, \n",
        "    freq = 'h', \n",
        "    n_jobs = -1\n",
        ")"
      ],
      "id": "8ceea3ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "h = 72\n",
        "step_size = 24\n",
        "partitons = 2\n",
        "n_windows=5\n",
        "method = \"conformal_distribution\"\n",
        "intervals = ConformalIntervals(h=72, n_windows=n_windows, method = method)\n",
        "levels = [95]"
      ],
      "id": "639099d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkt_df = sf.cross_validation(\n",
        "    df = ts,\n",
        "    h = h,\n",
        "    step_size = step_size,\n",
        "    n_windows =  partitons,\n",
        "    prediction_intervals = intervals,\n",
        "    level = levels\n",
        "  )"
      ],
      "id": "9f8cfd47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkt_df.head()"
      ],
      "id": "9022602b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_label = [str(s) for s in stats_models]  \n",
        "model_name = [type(s).__name__ for s in stats_models]  \n",
        "\n",
        "models_mapping = pd.DataFrame({\"model_label\": model_label, \n",
        "            \"model_name\": model_name})\n",
        "\n",
        "\n",
        "d1 = pd.melt(bkt_df, id_vars= [\"unique_id\", \"ds\", \"cutoff\"], \n",
        "value_vars= model_label, var_name = \"model_label\" , value_name = \"forecast\")\n",
        "d2 = pd.melt(bkt_df, id_vars= [\"unique_id\", \"ds\", \"cutoff\"], \n",
        "value_vars= lower, var_name = \"model_label\" , value_name = \"lower\")\n",
        "d2[\"model_label\"] = d2[\"model_label\"].str.replace(\"-lo-95\", \"\")\n",
        "d3 = pd.melt(bkt_df, id_vars= [\"unique_id\", \"ds\", \"cutoff\"], \n",
        "value_vars= upper, var_name = \"model_label\", value_name = \"upper\")\n",
        "d3[\"model_label\"] = d3[\"model_label\"].str.replace(\"-hi-95\", \"\")\n",
        "\n",
        "bkt_long = (\n",
        "    d1\n",
        ".merge(right = d2, how = \"left\", on = [\"unique_id\", \"ds\", \"cutoff\", \"model_label\"])\n",
        ".merge(right = d3, how = \"left\", on = [\"unique_id\", \"ds\", \"cutoff\", \"model_label\"])\n",
        ".merge(right =  models_mapping, how = \"left\", on = [\"model_label\"])\n",
        ".merge(right =  ts, how = \"left\", on = [\"unique_id\", \"ds\"])\n",
        ")\n",
        "bkt_long.head()"
      ],
      "id": "1774e95d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mape(y, yhat):\n",
        "    mape = mean(abs(y - yhat)/ y) \n",
        "    return mape\n",
        "\n",
        "def rmse(y, yhat):\n",
        "    rmse = (mean((y - yhat) ** 2 )) ** 0.5\n",
        "    return rmse\n",
        "\n",
        "def coverage(y, lower, upper):\n",
        "    coverage = sum((y <= upper) & (y >= lower)) / len(y)\n",
        "    return coverage\n",
        "\n",
        "\n",
        "def score(df):\n",
        "    mape_score = mape(y = df[\"y\"], yhat = df[\"forecast\"])\n",
        "    rmse_score = rmse(y = df[\"y\"], yhat = df[\"forecast\"])\n",
        "    coverage_score = coverage(y = df[\"y\"], lower = df[\"lower\"], upper = df[\"upper\"])\n",
        "    cols = [\"mape\",\"rmse\", \"coverage\"]\n",
        "    d = pd.Series([mape_score, rmse_score,  coverage_score], index=cols)\n",
        "\n",
        "    return d\n",
        "\n",
        "score_df = bkt_long.groupby([\"unique_id\", \"model_label\", \"model_name\", \"cutoff\"]).apply(score).reset_index()\n",
        "\n",
        "score_df.head()"
      ],
      "id": "030a30fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "leaderboard = score_df.groupby([\"unique_id\", \"model_label\", \"model_name\"]).agg({\"mape\": \"mean\", \"rmse\": \"mean\", \"coverage\": \"mean\"}).reset_index()\n",
        "\n",
        "leaderboard.sort_values(by = [\"mape\"])"
      ],
      "id": "f89d5e9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig = px.box(score_df, x=\"model_label\", y=\"rmse\", color=\"model_label\")\n",
        "fig.update_traces(boxpoints = 'all', jitter = 0.3, pointpos = -1.8, showlegend = False)\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Error Distribution\",\n",
        "    xaxis_title=\"Model\",\n",
        "    yaxis_title=\"RMSE\",\n",
        "    font=dict(family=\"Arial\", size=14, color=\"black\")\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "cacca9ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logging the Results with MLflow\n"
      ],
      "id": "0bf05c48"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cutoff = bkt_long[\"cutoff\"].unique()\n",
        "partitions_mapping = pd.DataFrame({\"cutoff\": cutoff, \"partition\": range(1, len(cutoff) + 1)})\n",
        "\n",
        "partitions_mapping\n",
        "\n",
        "score_df = score_df.merge(partitions_mapping, how = \"left\", on = [\"cutoff\"])\n",
        "score_df"
      ],
      "id": "58f086b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlflow\n",
        "\n",
        "experiment_name = \"stats_forecast\"\n",
        "\n",
        "mlflow_path = \"file:///mlruns\"\n",
        "\n",
        "tags = {\"h\": h,\n",
        "\"step_size\": step_size,\n",
        "\"partitions\": partitons,\n",
        "\"intervals_type\": \"ConformalIntervals\",\n",
        "\"intervals_h\": h,\n",
        "\"intervals_n_windows\": n_windows,\n",
        "\"intervals_method\": \"conformal_distribution\",\n",
        "\"levels\": levels }\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    mlflow.create_experiment(name = experiment_name,\n",
        "                            artifact_location= mlflow_path,\n",
        "                            tags = tags)\n",
        "    meta = mlflow.get_experiment_by_name(experiment_name)\n",
        "    print(f\"Set a new experiment {experiment_name}\")\n",
        "    print(\"Pulling the metadata\")\n",
        "except:\n",
        "    print(f\"Experiment {experiment_name} exists, pulling the metadata\")\n",
        "    meta = mlflow.get_experiment_by_name(experiment_name)"
      ],
      "id": "cf12e6b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "for index, row in score_df.iterrows():\n",
        "    run_name = row[\"model_label\"] + \"-\" + run_time \n",
        "    with mlflow.start_run(experiment_id = meta.experiment_id, \n",
        "                run_name = run_name,\n",
        "                tags = {\"type\": \"backtesting\",\n",
        "                \"partition\": row[\"partition\"], \n",
        "                \"unique_id\": row[\"unique_id\"],\n",
        "                \"model_label\": row[\"model_label\"],\n",
        "                \"model_name\": row[\"model_name\"],\n",
        "                \"run_name\": run_name}) as run:\n",
        "        model_params = {\n",
        "            \"model_name\": row[\"model_name\"],\n",
        "            \"model_label\": row[\"model_label\"],\n",
        "            \"partition\": row[\"partition\"]\n",
        "        }\n",
        "        mlflow.log_params(model_params)\n",
        "        mlflow.log_metric(\"mape\", row[\"mape\"])\n",
        "        mlflow.log_metric(\"rmse\", row[\"rmse\"])\n",
        "        mlflow.log_metric(\"coverage\", row[\"coverage\"])"
      ],
      "id": "f41d3a95",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}